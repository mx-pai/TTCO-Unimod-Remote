#!/usr/bin/env python3
"""
æ¯”èµ›æ•°æ®å¯¼å…¥å’Œæ ¼å¼è½¬æ¢æŒ‡å—
å°†æ¯”èµ›æ•°æ®æ ¼å¼è½¬æ¢ä¸ºUniMod1K/SPTå¯ä»¥ä½¿ç”¨çš„æ ¼å¼
"""

import os
import sys
import shutil
import cv2
import numpy as np
from pathlib import Path
import json

class CompetitionDataProcessor:
    """æ¯”èµ›æ•°æ®å¤„ç†å™¨"""

    def __init__(self, competition_data_root, output_root):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        Args:
            competition_data_root: æ¯”èµ›æ•°æ®æ ¹ç›®å½•
            output_root: è¾“å‡ºæ•°æ®æ ¹ç›®å½•ï¼ˆUniMod1Kæ ¼å¼ï¼‰
        """
        self.competition_root = Path(competition_data_root)
        self.output_root = Path(output_root)
        self.output_root.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ“‚ æ¯”èµ›æ•°æ®ç›®å½•: {self.competition_root}")
        print(f"ğŸ“‚ è¾“å‡ºæ•°æ®ç›®å½•: {self.output_root}")

    def analyze_competition_structure(self):
        """åˆ†ææ¯”èµ›æ•°æ®ç»“æ„"""
        print("ğŸ” åˆ†ææ¯”èµ›æ•°æ®ç»“æ„...")

        if not self.competition_root.exists():
            print(f"âŒ æ¯”èµ›æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.competition_root}")
            return False

        # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶å’Œç›®å½•
        print("\nğŸ“ æ•°æ®ç›®å½•ç»“æ„:")
        for item in self.competition_root.rglob("*"):
            if item.is_file():
                rel_path = item.relative_to(self.competition_root)
                print(f"ğŸ“„ {rel_path}")
            elif item.is_dir():
                rel_path = item.relative_to(self.competition_root)
                print(f"ğŸ“ {rel_path}/")

        return True

    def convert_sequence(self, seq_name, rgb_dir, depth_dir, text_file, gt_file):
        """
        è½¬æ¢å•ä¸ªåºåˆ—åˆ°UniMod1Kæ ¼å¼
        Args:
            seq_name: åºåˆ—åç§°
            rgb_dir: RGBå›¾åƒç›®å½•
            depth_dir: æ·±åº¦å›¾åƒç›®å½•
            text_file: æ–‡æœ¬æè¿°æ–‡ä»¶
            gt_file: æ ‡æ³¨æ–‡ä»¶
        """
        print(f"ğŸ”„ è½¬æ¢åºåˆ—: {seq_name}")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        seq_output = self.output_root / seq_name
        seq_output.mkdir(parents=True, exist_ok=True)

        color_output = seq_output / "color"
        depth_output = seq_output / "depth"
        color_output.mkdir(exist_ok=True)
        depth_output.mkdir(exist_ok=True)

        # è½¬æ¢RGBå›¾åƒ
        rgb_files = self._get_image_files(rgb_dir, ['.jpg', '.jpeg', '.png'])
        print(f"ğŸ“¸ RGBå›¾åƒæ•°é‡: {len(rgb_files)}")

        for i, rgb_file in enumerate(rgb_files):
            dst_name = f"{i+1:08d}.jpg"
            dst_path = color_output / dst_name
            if not dst_path.exists():
                shutil.copy2(rgb_file, dst_path)

        # è½¬æ¢æ·±åº¦å›¾åƒ
        depth_files = self._get_image_files(depth_dir, ['.png'])
        print(f"ğŸŒŠ æ·±åº¦å›¾åƒæ•°é‡: {len(depth_files)}")

        for i, depth_file in enumerate(depth_files):
            dst_name = f"{i+1:08d}.png"
            dst_path = depth_output / dst_name
            if not dst_path.exists():
                shutil.copy2(depth_file, dst_path)

        # å¤åˆ¶æ–‡æœ¬æè¿°
        if Path(text_file).exists():
            shutil.copy2(text_file, seq_output / "nlp.txt")
            print("âœ… æ–‡æœ¬æè¿°å·²å¤åˆ¶")

        # å¤åˆ¶æ ‡æ³¨æ–‡ä»¶
        if Path(gt_file).exists():
            shutil.copy2(gt_file, seq_output / "groundtruth_rect.txt")
            print("âœ… æ ‡æ³¨æ–‡ä»¶å·²å¤åˆ¶")

        print(f"âœ… åºåˆ— {seq_name} è½¬æ¢å®Œæˆ")
        return True

    def _get_image_files(self, directory, extensions):
        """è·å–æŒ‡å®šæ‰©å±•åçš„å›¾åƒæ–‡ä»¶"""
        directory = Path(directory)
        if not directory.exists():
            return []

        files = []
        for ext in extensions:
            files.extend(directory.glob(f"*{ext}"))
            files.extend(directory.glob(f"*{ext.upper()}"))

        return sorted(files)

    def batch_convert_from_structure(self, train_or_test="train"):
        """
        æ ¹æ®æ¯”èµ›æ•°æ®ç»“æ„æ‰¹é‡è½¬æ¢
        å‡è®¾æ¯”èµ›æ•°æ®ç»“æ„ä¸º:
        competition_data/
        â”œâ”€â”€ train/ (æˆ– test/)
        â”‚   â”œâ”€â”€ seq001/
        â”‚   â”‚   â”œâ”€â”€ rgb/
        â”‚   â”‚   â”œâ”€â”€ depth/
        â”‚   â”‚   â”œâ”€â”€ text.txt
        â”‚   â”‚   â””â”€â”€ gt.txt
        â”‚   â””â”€â”€ seq002/
        """
        print(f"ğŸ”„ æ‰¹é‡è½¬æ¢{train_or_test}æ•°æ®...")

        data_dir = self.competition_root / train_or_test
        if not data_dir.exists():
            print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            return False

        # éå†æ‰€æœ‰åºåˆ—ç›®å½•
        seq_dirs = [d for d in data_dir.iterdir() if d.is_dir()]
        print(f"ğŸ“Š æ‰¾åˆ° {len(seq_dirs)} ä¸ªåºåˆ—")

        for seq_dir in seq_dirs:
            seq_name = seq_dir.name

            # æŸ¥æ‰¾RGBå’Œæ·±åº¦ç›®å½•
            rgb_dir = seq_dir / "rgb"
            depth_dir = seq_dir / "depth"
            text_file = seq_dir / "text.txt"
            gt_file = seq_dir / "gt.txt"

            # æ£€æŸ¥å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not rgb_dir.exists():
                print(f"âš ï¸ RGBç›®å½•ä¸å­˜åœ¨: {seq_name}")
                continue

            if not depth_dir.exists():
                print(f"âš ï¸ æ·±åº¦ç›®å½•ä¸å­˜åœ¨: {seq_name}")
                continue

            # è½¬æ¢åºåˆ—
            self.convert_sequence(seq_name, rgb_dir, depth_dir, text_file, gt_file)

        print(f"âœ… {train_or_test}æ•°æ®æ‰¹é‡è½¬æ¢å®Œæˆ")
        return True

    def create_dataset_split(self):
        """åˆ›å»ºæ•°æ®é›†åˆ’åˆ†æ–‡ä»¶"""
        print("ğŸ“ åˆ›å»ºæ•°æ®é›†åˆ’åˆ†æ–‡ä»¶...")

        sequences = []
        for seq_dir in self.output_root.iterdir():
            if seq_dir.is_dir():
                sequences.append(seq_dir.name)

        sequences.sort()

        # åˆ›å»ºè®­ç»ƒé›†åˆ’åˆ†ï¼ˆå‡è®¾å‰80%ä¸ºè®­ç»ƒï¼Œå20%ä¸ºéªŒè¯ï¼‰
        split_point = int(len(sequences) * 0.8)
        train_seqs = sequences[:split_point]
        val_seqs = sequences[split_point:]

        # ä¿å­˜åˆ’åˆ†æ–‡ä»¶
        split_info = {
            'train': train_seqs,
            'val': val_seqs,
            'total': len(sequences)
        }

        with open(self.output_root / "dataset_split.json", 'w') as f:
            json.dump(split_info, f, indent=2)

        print(f"âœ… æ•°æ®é›†åˆ’åˆ†: è®­ç»ƒ{len(train_seqs)}, éªŒè¯{len(val_seqs)}")
        return split_info

    def verify_converted_data(self):
        """éªŒè¯è½¬æ¢åçš„æ•°æ®"""
        print("ğŸ” éªŒè¯è½¬æ¢åçš„æ•°æ®...")

        sequences = [d for d in self.output_root.iterdir() if d.is_dir()]
        print(f"ğŸ“Š æ€»åºåˆ—æ•°: {len(sequences)}")

        for seq_dir in sequences[:3]:  # éªŒè¯å‰3ä¸ªåºåˆ—
            print(f"\nğŸ” éªŒè¯åºåˆ—: {seq_dir.name}")

            # æ£€æŸ¥ç›®å½•ç»“æ„
            color_dir = seq_dir / "color"
            depth_dir = seq_dir / "depth"
            nlp_file = seq_dir / "nlp.txt"
            gt_file = seq_dir / "groundtruth_rect.txt"

            if color_dir.exists():
                color_files = len(list(color_dir.glob("*.jpg")))
                print(f"  âœ… RGBå›¾åƒ: {color_files} å¼ ")
            else:
                print(f"  âŒ RGBç›®å½•ä¸å­˜åœ¨")

            if depth_dir.exists():
                depth_files = len(list(depth_dir.glob("*.png")))
                print(f"  âœ… æ·±åº¦å›¾åƒ: {depth_files} å¼ ")
            else:
                print(f"  âŒ æ·±åº¦ç›®å½•ä¸å­˜åœ¨")

            if nlp_file.exists():
                with open(nlp_file, 'r') as f:
                    text = f.read().strip()
                print(f"  âœ… æ–‡æœ¬æè¿°: {text[:50]}...")
            else:
                print(f"  âŒ æ–‡æœ¬æè¿°ä¸å­˜åœ¨")

            if gt_file.exists():
                with open(gt_file, 'r') as f:
                    lines = f.readlines()
                print(f"  âœ… æ ‡æ³¨æ–‡ä»¶: {len(lines)} å¸§")
            else:
                print(f"  âŒ æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨")

        print("âœ… æ•°æ®éªŒè¯å®Œæˆ")

def create_data_loader_test():
    """åˆ›å»ºæ•°æ®åŠ è½½æµ‹è¯•è„šæœ¬"""

    test_code = '''#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®åŠ è½½
"""
import sys
import os
from pathlib import Path

# æ·»åŠ SPTè·¯å¾„
spt_path = "/root/autodl-tmp/UniMod1K/SPT"
sys.path.insert(0, spt_path)
sys.path.insert(0, os.path.join(spt_path, "lib"))

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½...")

    try:
        from lib.train.dataset.unimod1k import UniMod1K
        print("âœ… UniMod1Kæ•°æ®é›†ç±»å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•æ•°æ®é›†åˆå§‹åŒ–
        data_root = "/root/autodl-tmp/competition_data_converted"
        if Path(data_root).exists():
            dataset = UniMod1K(root=data_root, nlp_root=data_root)
            print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–æˆåŠŸï¼Œåºåˆ—æ•°: {len(dataset.sequence_list)}")

            # æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
            if len(dataset.sequence_list) > 0:
                seq_name = dataset.sequence_list[0]
                print(f"âœ… æµ‹è¯•åºåˆ—: {seq_name}")

                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„æ•°æ®åŠ è½½æµ‹è¯•
                return True
        else:
            print(f"âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
            return False

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    test_data_loading()
'''

    with open("test_data_loading.py", 'w') as f:
        f.write(test_code)
    print("âœ… åˆ›å»ºæ•°æ®åŠ è½½æµ‹è¯•è„šæœ¬: test_data_loading.py")

def main():
    """ä¸»å‡½æ•° - æ•°æ®å¯¼å…¥æŒ‡å—"""
    print("ğŸš€ æ¯”èµ›æ•°æ®å¯¼å…¥æŒ‡å—")
    print("="*50)

    print("""
ğŸ“‹ æ•°æ®å¯¼å…¥æ­¥éª¤:

1. ğŸ“¥ ä¸‹è½½æ¯”èµ›æ•°æ®
   - è®­ç»ƒé›†: 1000ä¸ªåºåˆ—ï¼Œ60,000ä¸ªRGB-Depthå›¾åƒå¯¹
   - éªŒè¯é›†: 50ä¸ªåºåˆ—ï¼Œ11,800ä¸ªå›¾åƒå¯¹
   - æµ‹è¯•é›†: 50ä¸ªåºåˆ—

2. ğŸ“ å‡†å¤‡æ•°æ®ç›®å½•ç»“æ„
   æ¯”èµ›æ•°æ®æ ¼å¼:
   competition_data/
   â”œâ”€â”€ train/
   â”‚   â”œâ”€â”€ seq001/
   â”‚   â”‚   â”œâ”€â”€ rgb/          # RGBå›¾åƒåºåˆ—
   â”‚   â”‚   â”œâ”€â”€ depth/        # æ·±åº¦å›¾åƒåºåˆ—
   â”‚   â”‚   â”œâ”€â”€ text.txt      # æ–‡æœ¬æè¿°
   â”‚   â”‚   â””â”€â”€ gt.txt        # æ ‡æ³¨æ–‡ä»¶
   â”‚   â””â”€â”€ ...
   â””â”€â”€ test/

3. ğŸ”„ è½¬æ¢æ•°æ®æ ¼å¼
   è½¬æ¢ä¸ºUniMod1Kæ ¼å¼:
   converted_data/
   â”œâ”€â”€ seq001/
   â”‚   â”œâ”€â”€ color/            # RGBå›¾åƒ (00000001.jpg, ...)
   â”‚   â”œâ”€â”€ depth/            # æ·±åº¦å›¾åƒ (00000001.png, ...)
   â”‚   â”œâ”€â”€ nlp.txt           # æ–‡æœ¬æè¿°
   â”‚   â””â”€â”€ groundtruth_rect.txt  # æ ‡æ³¨ [x,y,w,h]
   â””â”€â”€ ...

4. âš™ï¸ é…ç½®SPTæ•°æ®è·¯å¾„
5. ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½
    """)

    print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print("1. ä¿®æ”¹ä¸‹é¢çš„è·¯å¾„ä¸ºæ‚¨çš„å®é™…è·¯å¾„")
    print("2. è¿è¡Œæ•°æ®è½¬æ¢")
    print("3. éªŒè¯è½¬æ¢ç»“æœ")

    # ç¤ºä¾‹ä½¿ç”¨
    competition_data_root = "/root/autodl-tmp/competition_data"  # ä¿®æ”¹ä¸ºæ‚¨çš„æ¯”èµ›æ•°æ®è·¯å¾„
    output_root = "/root/autodl-tmp/competition_data_converted"   # è¾“å‡ºè·¯å¾„

    print(f"\nğŸ“‚ ç¤ºä¾‹è·¯å¾„é…ç½®:")
    print(f"   æ¯”èµ›æ•°æ®: {competition_data_root}")
    print(f"   è½¬æ¢è¾“å‡º: {output_root}")

    # åˆ›å»ºæ•°æ®åŠ è½½æµ‹è¯•è„šæœ¬
    create_data_loader_test()

    print(f"\nğŸ”§ è½¬æ¢æ•°æ®çš„Pythonä»£ç :")
    print(f"""
# åˆ›å»ºæ•°æ®å¤„ç†å™¨
processor = CompetitionDataProcessor(
    competition_data_root="{competition_data_root}",
    output_root="{output_root}"
)

# åˆ†ææ•°æ®ç»“æ„
processor.analyze_competition_structure()

# æ‰¹é‡è½¬æ¢è®­ç»ƒæ•°æ®
processor.batch_convert_from_structure("train")

# åˆ›å»ºæ•°æ®é›†åˆ’åˆ†
processor.create_dataset_split()

# éªŒè¯è½¬æ¢ç»“æœ
processor.verify_converted_data()
    """)

if __name__ == "__main__":
    main()